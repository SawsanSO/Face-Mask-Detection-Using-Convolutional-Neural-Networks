# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uJHXEI1ut7DMiQgnOYRHcIwcyForCiX1
"""

# My dataset is available in Google Drive; so I am accessing my drive from Colab
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Once this is executed, you will see your drive appearing on the left hand side

# ==========================================
# Import required libraries
# ==========================================
import os
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam

from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay

# ==========================================
# Define dataset paths
# ==========================================
base_dir  = '/content/drive/MyDrive/FaceMaskDataset'
train_dir = os.path.join(base_dir, 'train')
test_dir  = os.path.join(base_dir, 'test')

print("Training folders:", os.listdir(train_dir))
print("Testing folders:", os.listdir(test_dir))

# ==========================================
# Count images in train and test folders
# ==========================================
for category in ['with_mask', 'without_mask']:
    train_count = len(os.listdir(os.path.join(train_dir, category)))
    test_count  = len(os.listdir(os.path.join(test_dir, category)))
    print(f"{category} -> Train: {train_count}, Test: {test_count}")

# ==========================================
# Data preprocessing using ImageDataGenerator
# ==========================================
img_size = (224, 224)
batch_size = 32

# Training data generator with augmentation (to reduce overfitting)
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True
)

# Test data generator (no augmentation)
test_datagen = ImageDataGenerator(rescale=1./255)

train_data = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary'
)

test_data = test_datagen.flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)

print("Class indices:", train_data.class_indices)

# ==========================================
# Create CNN model (custom-made)
# ==========================================
cnn_model = Sequential()

cnn_model.add(Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)))
cnn_model.add(MaxPooling2D(2,2))

cnn_model.add(Conv2D(64, (3,3), activation='relu'))
cnn_model.add(MaxPooling2D(2,2))

cnn_model.add(Conv2D(128, (3,3), activation='relu'))
cnn_model.add(MaxPooling2D(2,2))

cnn_model.add(Flatten())
cnn_model.add(Dense(128, activation='relu'))   # Feature reduction
cnn_model.add(Dropout(0.5))                     # Reduce overfitting
cnn_model.add(Dense(1, activation='sigmoid'))  # Output layer (binary)

cnn_model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

cnn_model.summary()

# ==========================================
# Train CNN model
# ==========================================
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)

history_cnn = cnn_model.fit(
    train_data,
    epochs=10,
    validation_data=test_data,
    callbacks=[early_stop]
)

# ==========================================
# Plot training & validation accuracy
# ==========================================
plt.plot(history_cnn.history['accuracy'], label='train')
plt.plot(history_cnn.history['val_accuracy'], label='validation')
plt.title('Custom CNN - Accuracy')
plt.legend()
plt.show()

# ==========================================
# Plot training & validation loss
# ==========================================
plt.plot(history_cnn.history['loss'], label='train')
plt.plot(history_cnn.history['val_loss'], label='validation')
plt.title('Custom CNN - Loss')
plt.legend()
plt.show()

# ==========================================
# Predict test data using CNN
# ==========================================
predictions_cnn = cnn_model.predict(test_data)
predicted_labels_cnn = (predictions_cnn > 0.5).astype(int)

true_labels = test_data.classes

# Confusion Matrix
cm_cnn = confusion_matrix(true_labels, predicted_labels_cnn)
print("Confusion Matrix (CNN):")
print(cm_cnn)

# Classification Report
print("Classification Report (CNN):")
print(classification_report(true_labels, predicted_labels_cnn))

# ==========================================
# Plot Confusion Matrix (CNN) - for report figure
# ==========================================
disp = ConfusionMatrixDisplay(confusion_matrix=cm_cnn, display_labels=['with_mask','without_mask'])
disp.plot(values_format='d')
plt.title("Confusion Matrix - Custom CNN")
plt.show()

# ==========================================
# Using Pre-trained model - MobileNetV2 (Transfer Learning)
# ==========================================
from tensorflow.keras.applications import MobileNetV2

pretrained_model = MobileNetV2(
    weights='imagenet',
    include_top=False,
    input_shape=(224,224,3)
)

# Freeze all layers in the pre-trained model (so we train only the new classifier)
for layer in pretrained_model.layers:
    layer.trainable = False

# ==========================================
# Create a new model by adding custom layers on top of MobileNetV2
# ==========================================
mobilenet_model = Sequential()

mobilenet_model.add(pretrained_model)
mobilenet_model.add(GlobalAveragePooling2D())
mobilenet_model.add(Dense(128, activation='relu'))   # feature reduction
mobilenet_model.add(Dropout(0.3))                    # reduce overfitting
mobilenet_model.add(Dense(1, activation='sigmoid'))  # binary output

mobilenet_model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

mobilenet_model.summary()

# ==========================================
# Train MobileNetV2 model
# ==========================================
early_stop_mobilenet = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)

history_mobilenet = mobilenet_model.fit(
    train_data,
    epochs=10,
    validation_data=test_data,
    callbacks=[early_stop_mobilenet]
)

# ==========================================
# Plot training & validation accuracy (MobileNetV2)
# ==========================================
plt.plot(history_mobilenet.history['accuracy'], label='train')
plt.plot(history_mobilenet.history['val_accuracy'], label='validation')
plt.title('MobileNetV2 - Accuracy')
plt.legend()
plt.show()

# ==========================================
# Plot training & validation loss (MobileNetV2)
# ==========================================
plt.plot(history_mobilenet.history['loss'], label='train')
plt.plot(history_mobilenet.history['val_loss'], label='validation')
plt.title('MobileNetV2 - Loss')
plt.legend()
plt.show()

# ==========================================
# Predict test data using MobileNetV2
# ==========================================
predictions_m = mobilenet_model.predict(test_data)
predicted_labels_m = (predictions_m > 0.5).astype(int)

# Confusion Matrix
cm_m = confusion_matrix(true_labels, predicted_labels_m)
print("Confusion Matrix (MobileNetV2):")
print(cm_m)

# Classification Report
print("Classification Report (MobileNetV2):")
print(classification_report(true_labels, predicted_labels_m))

# ==========================================
# Plot Confusion Matrix (MobileNetV2) - for report figure
# ==========================================
disp2 = ConfusionMatrixDisplay(confusion_matrix=cm_m, display_labels=['with_mask','without_mask'])
disp2.plot(values_format='d')
plt.title("Confusion Matrix - MobileNetV2")
plt.show()

# ==========================================
# Create comparison table using key metrics
# ==========================================
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pandas as pd

cnn_acc = accuracy_score(true_labels, predicted_labels_cnn)
cnn_prec = precision_score(true_labels, predicted_labels_cnn)
cnn_rec = recall_score(true_labels, predicted_labels_cnn)
cnn_f1 = f1_score(true_labels, predicted_labels_cnn)

m_acc = accuracy_score(true_labels, predicted_labels_m)
m_prec = precision_score(true_labels, predicted_labels_m)
m_rec = recall_score(true_labels, predicted_labels_m)
m_f1 = f1_score(true_labels, predicted_labels_m)

df_compare = pd.DataFrame({
    "Model": ["Custom CNN", "MobileNetV2 (Pre-trained)"],
    "Accuracy": [cnn_acc, m_acc],
    "Precision": [cnn_prec, m_prec],
    "Recall": [cnn_rec, m_rec],
    "F1-score": [cnn_f1, m_f1]
})

df_compare